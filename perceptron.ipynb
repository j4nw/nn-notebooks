{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    if x < 0: return -1\n",
    "    elif x > 0: return 1\n",
    "    return 0\n",
    "\n",
    "def perceptron_train(data, learning_coeff, max_iterations):\n",
    "    best_age = age = 0\n",
    "    best_weights = weights = np.random.rand(data.shape[1] - 1)\n",
    "    best_bias = bias = np.random.random()\n",
    "    for _ in range(max_iterations):\n",
    "        d = data[np.random.randint(len(data))]\n",
    "        x, c = d[:-1], d[-1]\n",
    "        o = perceptron_respond(x, weights, best_bias)\n",
    "        if (o == c):\n",
    "            age += 1\n",
    "            if age > best_age:\n",
    "                best_age = age\n",
    "                best_weights = weights\n",
    "                best_bias = bias\n",
    "        else:\n",
    "            weights = [w + learning_coeff * c * x[i] for i, w in enumerate(weights)]\n",
    "            bias += learning_coeff * c\n",
    "            age = 0\n",
    "    return best_weights, best_bias\n",
    "\n",
    "def perceptron_respond(datapoint, weights, bias):\n",
    "    return activation(np.dot(datapoint, weights) + bias)\n",
    "\n",
    "def accuracy(test_data, weights, bias):\n",
    "    correct = 0\n",
    "    for d in test_data:\n",
    "        x, c = d[:-1], d[-1]\n",
    "        o = perceptron_respond(x, weights, bias)\n",
    "        if o == c:\n",
    "            correct += 1\n",
    "    return correct / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "weights: [0.24724238754964004, 0.24400949358701557, -0.5106023652738516, -0.3955046317046136]\n",
      "bias: 0.9820589444094501\n",
      "accuracy: 100.0 %\n",
      "\n",
      "B\n",
      "weights: [0.35484664155854884, 0.3123673052789325, -0.5833294292313116, -0.44128408804268776]\n",
      "bias: 0.5193298847390763\n",
      "accuracy: 100.0 %\n",
      "\n",
      "C\n",
      "weights: [0.15538891751291142, 0.08869877957339097, -0.35265843246014994, -0.2443205083889679]\n",
      "bias: 0.8706911579417147\n",
      "accuracy: 85.0 %\n",
      "\n",
      "D\n",
      "weights: [0.36410898198029484, 0.4124507271998383, -0.5649884462198224, -0.5537361749900144]\n",
      "bias: 0.3026984063744578\n",
      "accuracy: 80.0 %\n",
      "\n",
      "E\n",
      "weights: [0.3015190592664051, 0.4071419548274303, -0.5411923870376268, -0.49909238732460337]\n",
      "bias: 0.5302863835268653\n",
      "accuracy: 100.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005\n",
    "max_iterations = 10000\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "for c in letters:\n",
    "    training_data = np.loadtxt(f'data/iris_2vs3_{c}_tr.txt')\n",
    "    weights, bias = perceptron_train(training_data, learning_rate, max_iterations)\n",
    "    test_data = np.loadtxt(f'data/iris_2vs3_{c}_te.txt')\n",
    "    a = accuracy(test_data, weights, bias)\n",
    "    \n",
    "    print(c)\n",
    "    print('weights:', weights)\n",
    "    print('bias:', bias)\n",
    "    print('accuracy:', a * 100, '%')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
