{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    if x < 0: return -1\n",
    "    elif x > 0: return 1\n",
    "    return 0\n",
    "\n",
    "def perceptron_train(data, learning_rate, max_iterations):\n",
    "    best_age = age = 0\n",
    "    best_weights = weights = np.random.rand(data.shape[1] - 1)\n",
    "    best_bias = bias = np.random.random()\n",
    "    for _ in range(max_iterations):\n",
    "        d = data[np.random.randint(len(data))]\n",
    "        x, c = d[:-1], d[-1]\n",
    "        o = perceptron_respond(x, weights, best_bias)\n",
    "        if (o == c):\n",
    "            age += 1\n",
    "            if age > best_age:\n",
    "                best_age = age\n",
    "                best_weights = weights\n",
    "                best_bias = bias\n",
    "        else:\n",
    "            weights = [w + learning_rate * c * x[i] for i, w in enumerate(weights)]\n",
    "            bias += learning_rate * c\n",
    "            age = 0\n",
    "    return best_weights, best_bias\n",
    "\n",
    "def perceptron_respond(datapoint, weights, bias):\n",
    "    return activation(np.dot(datapoint, weights) + bias)\n",
    "\n",
    "def accuracy(test_data, weights, bias):\n",
    "    correct = 0\n",
    "    for d in test_data:\n",
    "        x, c = d[:-1], d[-1]\n",
    "        o = perceptron_respond(x, weights, bias)\n",
    "        if o == c:\n",
    "            correct += 1\n",
    "    return correct / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "weights: [0.24194951348649266, 0.26294062325085266, -0.37966209024923475, -0.4038172988393777]\n",
      "bias: 0.3784485959826611\n",
      "accuracy: 100.0 %\n",
      "\n",
      "B\n",
      "weights: [0.2275368884854422, 0.2942815316708829, -0.5496940653698961, -0.20838174340081694]\n",
      "bias: 0.7600584205029205\n",
      "accuracy: 100.0 %\n",
      "\n",
      "C\n",
      "weights: [0.23843111751773505, 0.2157363077323438, -0.41809727322110735, -0.28062450544793605]\n",
      "bias: 0.45127274142801976\n",
      "accuracy: 95.0 %\n",
      "\n",
      "D\n",
      "weights: [0.39964946477445273, 0.2729061381360356, -0.6500257004842617, -0.4251267614528527]\n",
      "bias: 0.6979163592768429\n",
      "accuracy: 85.0 %\n",
      "\n",
      "E\n",
      "weights: [0.10117263628882892, 0.23427002007138914, -0.2836271978968097, -0.4694751298980888]\n",
      "bias: 0.8900562531418591\n",
      "accuracy: 100.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005\n",
    "max_iterations = 10000\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "for c in letters:\n",
    "    training_data = np.loadtxt(f'data/iris_2vs3_{c}_tr.txt')\n",
    "    weights, bias = perceptron_train(training_data, learning_rate, max_iterations)\n",
    "    test_data = np.loadtxt(f'data/iris_2vs3_{c}_te.txt')\n",
    "    a = accuracy(test_data, weights, bias)\n",
    "    \n",
    "    print(c)\n",
    "    print('weights:', weights)\n",
    "    print('bias:', bias)\n",
    "    print('accuracy:', a * 100, '%')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
